{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1336f1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LegacyCodes.mails import get_gmail_service, fetch_messages, length_of_mail\n",
    "from googleapiclient.errors import HttpError\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfaeb318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=1063709963049-89rkbl03gv9uug4dvee5tsblpnfdr8ct.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A51542%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fgmail.readonly&state=cWoBygmCqdk6XmdfEWy0xRNdIfy37k&access_type=offline\n",
      "Fetched 500 messages...\n",
      "Fetched 827 messages...\n",
      "\n",
      " Saved 827 messages to raw_emails.parquet\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    service = get_gmail_service()\n",
    "    fetch_messages(service) # Fetch messages and save to Parquet file\n",
    "except HttpError as err:\n",
    "    print(f\"An error occurred: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a8f2512",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"raw_emails.parquet\")\n",
    "df[\"subject\"] = df[\"subject\"].fillna(\"\").str.slice(0, 180)\n",
    "df[\"sender\"] = df[\"sender\"].fillna(\"\").str.slice(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d3df87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sender</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197da530e85a33d4</td>\n",
       "      <td>Sakshi &lt;sakshi.raheja@newsletters.analyticsvid...</td>\n",
       "      <td>Your path to mastering AI starts here, Batuhan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197d6b614d1dd70f</td>\n",
       "      <td>Google &lt;no-reply@accounts.google.com&gt;</td>\n",
       "      <td>2 Adımlı Doğrulama açıldı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197d6b60fee7c619</td>\n",
       "      <td>Google &lt;no-reply@accounts.google.com&gt;</td>\n",
       "      <td>Güvenlik uyarısı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197d4e36b764bba1</td>\n",
       "      <td>Batuhan &lt;batuhancomert2024@gmail.com&gt;</td>\n",
       "      <td>Cover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>197d2f219baea3c8</td>\n",
       "      <td>Quora Digest &lt;english-quora-digest@quora.com&gt;</td>\n",
       "      <td>What are popular Turkish names that are Turkic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                             sender  \\\n",
       "0  197da530e85a33d4  Sakshi <sakshi.raheja@newsletters.analyticsvid...   \n",
       "1  197d6b614d1dd70f              Google <no-reply@accounts.google.com>   \n",
       "2  197d6b60fee7c619              Google <no-reply@accounts.google.com>   \n",
       "3  197d4e36b764bba1              Batuhan <batuhancomert2024@gmail.com>   \n",
       "4  197d2f219baea3c8      Quora Digest <english-quora-digest@quora.com>   \n",
       "\n",
       "                                             subject  \n",
       "0     Your path to mastering AI starts here, Batuhan  \n",
       "1                          2 Adımlı Doğrulama açıldı  \n",
       "2                                   Güvenlik uyarısı  \n",
       "3                                              Cover  \n",
       "4  What are popular Turkish names that are Turkic...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec4dff2",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "exception: access violation reading 0x0000000000000000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_cpp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Llama\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the quantized model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m llm \u001b[38;5;241m=\u001b[39m Llama(\n\u001b[0;32m      5\u001b[0m     model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/llama-3-8b-instruct.Q4_K_M.gguf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     n_ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m,\n\u001b[0;32m      7\u001b[0m     n_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,  \u001b[38;5;66;03m# Tune based on your CPU\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\comer\\anaconda3\\Lib\\site-packages\\llama_cpp\\llama.py:206\u001b[0m, in \u001b[0;36mLlama.__init__\u001b[1;34m(self, model_path, n_gpu_layers, split_mode, main_gpu, tensor_split, vocab_only, use_mmap, use_mlock, kv_overrides, seed, n_ctx, n_batch, n_ubatch, n_threads, n_threads_batch, rope_scaling_type, pooling_type, rope_freq_base, rope_freq_scale, yarn_ext_factor, yarn_attn_factor, yarn_beta_fast, yarn_beta_slow, yarn_orig_ctx, logits_all, embedding, offload_kqv, flash_attn, op_offloat, swa_full, no_perf, last_n_tokens_size, lora_base, lora_scale, lora_path, numa, chat_format, chat_handler, draft_model, tokenizer, type_k, type_v, spm_infill, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Llama\u001b[38;5;241m.\u001b[39m__backend_initialized:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress_stdout_stderr(disable\u001b[38;5;241m=\u001b[39mverbose):\n\u001b[1;32m--> 206\u001b[0m         llama_cpp\u001b[38;5;241m.\u001b[39mllama_backend_init()\n\u001b[0;32m    207\u001b[0m     Llama\u001b[38;5;241m.\u001b[39m__backend_initialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(numa, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[1;31mOSError\u001b[0m: exception: access violation reading 0x0000000000000000"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# Load the quantized model\n",
    "llm = Llama(\n",
    "    model_path=\"./models/llama-3-8b-instruct.Q4_K_M.gguf\",\n",
    "    n_ctx=2048,\n",
    "    n_threads=6,  # Tune based on your CPU\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5157ef11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
